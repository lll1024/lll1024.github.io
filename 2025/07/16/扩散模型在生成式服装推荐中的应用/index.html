<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jarviliu.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.23.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="扩散模型在生成式服装推荐中的应用作者信息: Yiyan Xu, Wenjie Wang, Fuli Feng (中国科学技术大学) Yunshan Ma, Jizhi Zhang, Xiangnan He (新加坡国立大学) 摘要 时尚领域的服装推荐（OR）经历了两个阶段的演变：预定义服装推荐和个性化服装搭配。然而，这两个阶段都受到现有时尚产品的限制，从而限制了它们在满足用户多样化时尚需求方面的有">
<meta property="og:type" content="article">
<meta property="og:title" content="Magic House">
<meta property="og:url" content="https://jarviliu.github.io/2025/07/16/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%9C%A8%E7%94%9F%E6%88%90%E5%BC%8F%E6%9C%8D%E8%A3%85%E6%8E%A8%E8%8D%90%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/index.html">
<meta property="og:site_name" content="Magic House">
<meta property="og:description" content="扩散模型在生成式服装推荐中的应用作者信息: Yiyan Xu, Wenjie Wang, Fuli Feng (中国科学技术大学) Yunshan Ma, Jizhi Zhang, Xiangnan He (新加坡国立大学) 摘要 时尚领域的服装推荐（OR）经历了两个阶段的演变：预定义服装推荐和个性化服装搭配。然而，这两个阶段都受到现有时尚产品的限制，从而限制了它们在满足用户多样化时尚需求方面的有">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-07-15T18:04:43.984Z">
<meta property="article:modified_time" content="2025-07-15T18:04:43.985Z">
<meta property="article:author" content="L">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://jarviliu.github.io/2025/07/16/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%9C%A8%E7%94%9F%E6%88%90%E5%BC%8F%E6%9C%8D%E8%A3%85%E6%8E%A8%E8%8D%90%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jarviliu.github.io/2025/07/16/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%9C%A8%E7%94%9F%E6%88%90%E5%BC%8F%E6%9C%8D%E8%A3%85%E6%8E%A8%E8%8D%90%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","path":"2025/07/16/扩散模型在生成式服装推荐中的应用/","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title> | Magic House</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Magic House</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%9C%A8%E7%94%9F%E6%88%90%E5%BC%8F%E6%9C%8D%E8%A3%85%E6%8E%A8%E8%8D%90%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-number">1.</span> <span class="nav-text">扩散模型在生成式服装推荐中的应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E7%89%87%E7%BF%BB%E8%AF%91"><span class="nav-number">1.1.</span> <span class="nav-text">图片翻译</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%BE%E7%89%87%E7%BF%BB%E8%AF%91-1"><span class="nav-number">1.2.</span> <span class="nav-text">图片翻译</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">L</p>

  
    <p class="site-author-email" itemprop="email">
      <a href="mailto:jarviliu@gmail.com">jarviliu@gmail.com</a>
    </p>

  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jarviliu.github.io/2025/07/16/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%9C%A8%E7%94%9F%E6%88%90%E5%BC%8F%E6%9C%8D%E8%A3%85%E6%8E%A8%E8%8D%90%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="L">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Magic House">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Magic House">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-07-16 02:04:43" itemprop="dateCreated datePublished" datetime="2025-07-16T02:04:43+08:00">2025-07-16</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="扩散模型在生成式服装推荐中的应用"><a href="#扩散模型在生成式服装推荐中的应用" class="headerlink" title="扩散模型在生成式服装推荐中的应用"></a>扩散模型在生成式服装推荐中的应用</h1><p><strong>作者信息:</strong></p>
<p>Yiyan Xu, Wenjie Wang, Fuli Feng (中国科学技术大学)</p>
<p>Yunshan Ma, Jizhi Zhang, Xiangnan He (新加坡国立大学)</p>
<p><strong>摘要</strong></p>
<p>时尚领域的服装推荐（OR）经历了两个阶段的演变：预定义服装推荐和个性化服装搭配。然而，这两个阶段都受到现有时尚产品的限制，从而限制了它们在满足用户多样化时尚需求方面的有效性。最近，人工智能生成内容的出现为服装推荐提供了超越这些限制的机会，展示了个性化服装生成和推荐的潜力。</p>
<p>为此，我们引入了一项名为生成式服装推荐（GOR）的新任务，旨在生成一套时尚图片并将其组合成视觉上兼容的、为特定用户量身定制的服装。GOR 的关键目标在于生成服装的高保真度、兼容性和个性化。为了实现这些目标，我们提出了一种名为 DiFashion 的生成式服装推荐模型，它利用卓越的扩散模型来完成多张时尚图片的并行生成。为了确保这三个目标，我们设计了三种条件来指导并行生成过程，并采用无分类器指导来增强生成图片与条件之间的对齐。我们将 DiFashion 应用于个性化填空和 GOR 任务，并在 iFashion 和 Polyvore-U 数据集上进行了广泛的实验。定量和人工参与的定性评估证明了 DiFashion 优于竞争基线。</p>
<p><strong>关键词</strong></p>
<p>生成式服装推荐，生成式推荐模型，扩散模型</p>
<p><strong>ACM 参考格式:</strong></p>
<p>Yiyan Xu, Wenjie Wang, Fuli Feng, Yunshan Ma, Jizhi Zhang, and Xiangnan He. 2024. Diffusion Models for Generative Outfit Recommendation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’24), July 14–18, 2024, Washington, DC, USA. ACM, New York, NY, USA, 11 pages. <a target="_blank" rel="noopener" href="https://doi.org/10.1145/3626772.3657719">https://doi.org/10.1145/3626772.3657719</a></p>
<p><strong>1 引言</strong></p>
<p>时尚显著影响着人类的日常生活，反映了个人的个性和审美。然而，许多消费者常常难以将不同的时尚元素组合成一套兼容的服装，这主要是由于时尚专业知识有限 [5,9,10]。因此，服装推荐（OR）已成为时尚领域的一项重要任务，提供个性化的服装级时尚建议。通过推荐搭配得当的服装，服装推荐简化了时尚决策过程，使消费者免于协调各种时尚产品所需的额外时间和精力。</p>
<p>服装推荐的演变，如图1顶部所示，分为两个阶段：</p>
<ul>
<li><p><strong>预定义服装推荐（POR）:</strong> 服装推荐最初被定义为一项服装级检索任务，旨在为用户检索现有的搭配得当的服装 [18,28,33,34,54]。然而，其有效性受到可用预定义服装数量和多样性有限的阻碍，因此不足以满足用户多样化的时尚偏好 [17]。</p>
</li>
<li><p><strong>个性化服装搭配:</strong> 这项任务侧重于在项目级别检索一系列时尚产品，并将其组合成视觉上和谐的服装 [12,17,20]。通过组合新的、个性化的、兼容的服装，这项任务部分缓解了预定义服装推荐的多样性限制。然而，现有时尚产品可能无法完全符合用户的理想期望，尤其是在颜色、图案、剪裁和设计等细节方面 [25,52]。</p>
</li>
</ul>
<p>随着人工智能生成内容（AIGC）的蓬勃发展 [7,14,41]，服装推荐展现出超越现有时尚产品的潜力，从而实现时尚产品的定制生成和搭配。鉴于此，我们提出了一项名为生成式服装推荐（GOR）的新任务。如图1所示，GOR 旨在</p>
<p>生成一套新的个性化时尚产品，以构成视觉上兼容的、满足特定用户时尚品味的服装。通过生成新的服装，GOR 可以随时在时尚商品数据库 [48,52,53] 中检索类似产品，或者转向时尚制造商 [43] 进行定制。这项生成任务有望提供真正量身定制和多样化的时尚服装，与用户的理想时尚需求紧密契合。</p>
<p>为了有效利用生成模型实现 GOR，三个关键标准至关重要：1）高保真度，要求生成的图像准确描绘时尚产品的细节；2）兼容性，确保生成的时尚图像在服装中和谐统一；3）个性化，要求生成的服装与特定用户偏好保持一致。扩散模型（DMs）以其在图像合成方面的最先进能力而闻名，具有生成高质量时尚图像的潜力 [11,22,41]。以前的研究已经使用扩散模型从文本提示和其他模态的条件 [8,19,26,44,49] 生成单个时尚图像。然而，GOR 需要生成多个具有内部兼容性的时尚图像，用于服装搭配和推荐，强调生成的服装与从用户信息（例如，交互历史和用户特征）中捕获的个人时尚品味的一致性。</p>
<p>为了为用户生成高保真度、兼容且个性化的服装，我们提出了 DiFashion，这是一种从扩散模型改编而来的生成式服装推荐模型。通常，DiFashion 包含两个关键过程：逐渐破坏服装图像（在正向扩散过程中通过添加高斯噪声），并在反向阶段并行生成。三个条件，即类别提示、相互条件和历史条件，是指导并行生成过程以追求 GOR 三个标准的关键。具体来说，1）为了高保真度，DiFashion 采用类别提示来确保类别一致性，并为这三个条件采用无分类器指导 [6,23] 来提高图像质量和生成图像与条件之间的对齐；2）为了确保兼容性，设计了一个相互编码器，将同一服装内的时尚图像在不同噪声水平下编码为兼容性信息，作为相互条件；3）为了个性化，DiFashion 包含一个历史编码器，利用用户与时尚产品的历史交互，捕获他们的个性化品味作为历史条件。</p>
<p>我们将 DiFashion 应用于两项任务：个性化填空（PFITB）和 GOR 任务（参见图2中的插图）。给定用户的交互历史和指定类别，PFITB 任务涉及生成一个能够无缝补充不完整服装的时尚产品，而 GOR 任务需要生成一个完整的兼容服装。我们在 iFashion [12] 和 Polyvore-U [34] 数据集上进行了广泛的实验，并将 DiFashion 与各种基线（包括生成模型和基于检索的模型）进行了比较，证明了我们提出的 DiFashion 在 PFITB 和 GOR 任务中的优越性。我们已在 <a target="_blank" rel="noopener" href="https://github.com/YiyanXu/DiFashion">https://github.com/YiyanXu/DiFashion</a> 发布了我们的代码和数据。</p>
<p>总而言之，这项工作的主要贡献如下：</p>
<ul>
<li>我们提出了一项新的生成式服装推荐任务，利用生成式 AI 为用户创建个性化服装。这项举措开创了服装推荐的一个有前景的途径，并有助于形成更个性化的时尚格局。</li>
<li>我们提出了 DiFashion，这是一种生成式服装推荐模型，它擅长并行生成多个时尚图像，巧妙地追求各种生成目标。</li>
<li>我们在 iFashion 和 Polyvore-U 数据集上进行了大量实验，其中定量和人工参与的定性评估证明了 DiFashion 在 PFITB 和 GOR 任务上的卓越性能。</li>
</ul>
<p><strong>2 预备知识</strong></p>
<p>扩散模型（DMs）采用具有 T 个扩散步骤的马尔可夫链进行图像合成，涉及正向和反向过程。</p>
<ul>
<li><p><strong>正向过程。</strong> 给定图像 x0 ∼ q(x0)，正向扩散过程通过添加高斯噪声来破坏图像：</p>
<p>q(xt |xt−1) &#x3D; N(xt; √1−βt xt−1, βtI), (1)</p>
<p>其中 t ∈ {1,…,T} 表示扩散步骤，βt ∈ (0,1) 控制在每个步骤 t 添加的噪声尺度。当 T → ∞ 时，图像 xT 收敛到标准高斯噪声 xT ∼ N(0,I) [22]。</p>
</li>
<li><p><strong>反向过程。</strong> 从一个几乎纯噪声的图像 xT 开始，扩散模型通过去噪转换迭代地消除噪声：</p>
<p>pθ(xt−1 |xt) &#x3D; N(xt−1; μθ(xt, t), Σθ(xt, t)), (2)</p>
<p>其中 μθ 和 Σθ 表示由神经网络（例如，U-Net [22] 或 Transformer [39]）参数化的反向高斯分布的近似均值和协方差。为了保持训练稳定性，通常忽略 Σθ 的学习 [22]，而去噪转换均值 μθ 可以进一步分解为：</p>
<p>μθ(xt, t) &#x3D; (1&#x2F;√αt) * (xt - (1-αt)&#x2F;√(1-ᾱt) * εθ(xt, t)), (3)</p>
<p>其中 αt &#x3D; 1-βt, ᾱt &#x3D; Πt’t&#x3D;1 αt’，εθ 学习预测确定 x0 的源噪声 ε ∼ N(0,I) [35]。</p>
</li>
<li><p><strong>优化。</strong> 去噪神经网络 θ 可以使用以下简化目标进行训练 [22]：</p>
<p>Lθ &#x3D; E t,ε∼N(0,I) [∥ε - εθ(xt, t)∥2 2], (4)</p>
</li>
<li><p><strong>生成。</strong> 训练 θ 后，扩散模型随机采样一个纯噪声 xT ∼ N(0,I) 作为初始状态，并根据公式 (2) 和 (3) 迭代地进行生成。扩散模型以迭代方式生成图像，使得通过多步生成过程解决优化问题成为可能。首先，让我们考虑并行生成 n 个图像，其中每个图像 ik,T ∼ N(0,I) 都是从均匀采样的噪声中获得的，而无需深入实现细节。从 xT 开始，扩散模型逐渐重复生成过程 OT → OT-1 → ··· → O0，从而得到不同噪声水平下的 T 套服装。尽管公式 (5b) 中不完整服装 O’k 的准确过程是无法实现的，但 O’k,t &#x3D; Ot {ik,t} 可以作为在每个扩散步骤 t ∈ {1,…,T} 生成 ik,t-1 的替代。形式上，公式 (5) 中的优化问题可以近似表示为：</p>
<p>u, OT &#x3D; {ik,T}nk&#x3D;1 →θ O0 &#x3D; {ik,0}nk&#x3D;1, (6a)</p>
<p>s.t. ik,t-1 &#x3D; argmaxi Pθ(i|ik,t, O’k,t, u), (6b)</p>
<p>其中 k &#x3D; 1,…,n 且 t &#x3D; 1,…,T。</p>
<p>请注意，初始状态 OT 等同于公式 (5a) 中的 ∅，因为每个元素 ik,T 都是从标准高斯噪声中采样的，不包含任何信息。</p>
</li>
</ul>
<p><strong>3 生成式服装推荐</strong></p>
<p><strong>3.1 任务表述</strong></p>
<p>GOR 任务旨在合成一组新颖的时尚产品图像，以构成与个性化用户偏好相符的视觉兼容服装。形式上，给定用户信息 u（例如，交互历史和用户特征），GOR 生成一套服装 O &#x3D; {ik}nk&#x3D;1，其中 ik 表示单个时尚物品，以满足三个标准：高保真度、兼容性和个性化。我们可以将 GOR 定义为以下优化问题：</p>
<pre><code>u, ∅ →θ O = &#123;ik&#125;nk=1, (5a)

s.t. ik = argmaxi Pθ(i|O&#39;k, u), k = 1,...,n. (5b)

这里，用户信息 u 以及空集 ∅ 作为带有参数 θ 的生成模型的输入，从而生成服装 O。生成过程受到公式 (5b) 的约束，其中 Pθ(·) 表示生成每个物品的条件概率。模型参数 θ 被优化以生成最兼容的匹配物品 ik，用于每个不完整的服装 O&#39;k = O\&#123;ik&#125;，同时与用户偏好保持一致。

然而，由于缺乏明确的起点和在优化过程中不断演变的约束，这个优化问题是难以处理的。一个直观的解决方案 [12,20] 通过将服装建模为有序序列，仅考虑来自预排序物品的影响来指导 ik 的生成，从而简化了约束，使得优化变得可行。尽管如此，这并不是理想的解决方案，因为序列中先前生成的物品并未完全优化，这与公式 (5) 中通过目标函数进行优化的目的相悖 [13,17]。
</code></pre>
<p><strong>3.2 DiFashion</strong></p>
<p>为了根据用户信息生成一组兼容的时尚图像，如图3所示，DiFashion 在正向过程中逐渐将多个时尚图像破坏为几乎纯噪声，然后通过 U-Net 进行并行反向重建。在反向过程中，DiFashion 考虑了三个关键输入条件：1）类别提示确保</p>
<p>生成的时尚图像与指定类别对齐；2）相互条件保证生成服装内部的兼容性；3）历史条件确保生成的服装与用户偏好紧密匹配。这些条件协同作用，指导反向过程，从而生成视觉上吸引人且符合用户独特时尚品味的服装。请注意，图3中仅展示了服装中的四件物品，但 DiFashion 可以轻松同时处理更多物品。</p>
<p>3.2.1 扩散过程。DiFashion 涉及两个关键的扩散过程：正向过程通过添加高斯噪声来破坏服装图像，反向过程学习并行重建这些图像，两者都在低维潜在空间而不是原始像素空间中执行。遵循 Stable Diffusion (SD) [41]，我们利用预训练的自编码器，其中包含编码器 E 和解码器 D，将服装 O0 &#x3D; {ik,0}nk&#x3D;1 压缩到潜在空间 E(O0) &#x3D; {E(ik,0)}nk&#x3D;1。在反向过程结束后，服装使用解码器 D 恢复到像素空间。为简洁起见，我们使用缩写 O0 和 ik,0 来表示扩散过程，省略了有关 E 和 D 的细节，如图3所示。</p>
<ul>
<li><p><strong>正向过程。</strong> 给定服装 O0 &#x3D; {ik,0}nk&#x3D;1，其中 ik,0 表示服装中的时尚产品，服装的正向转换独立地在每个图像上执行，定义为：</p>
<p>q(Ot|Ot-1) &#x3D; Πnk&#x3D;1 q(ik,t|ik,t-1)</p>
<p>&#x3D; Πnk&#x3D;1 N(ik,t; √1-βt ik,t-1, βtI), (7)</p>
<p>其中 βt ∈ (0,1) 控制在每个扩散步骤 t ∈ {1,…,T} 添加的噪声尺度。当 T → ∞ 时，服装 OT 收敛到一组标准高斯噪声 [22]。</p>
</li>
<li><p><strong>反向过程。</strong> 从几乎纯噪声 OT 开始，反向过程通过以下去噪转换步骤并行逐渐重建服装中的时尚图像：</p>
<p>pθ(Ot-1|Ot) &#x3D; Πnk&#x3D;1 pθ(ik,t-1|Ot),</p>
<p>&#x3D; N(ik,t-1; μθ(Ot,t), Σθ(Ot,t)), (8)</p>
<p>其中 μθ 和 Σθ 表示由具有可学习参数 θ 的 U-Net 输出的高斯参数。步骤 t 的服装 Ot &#x3D; {ik,t} ∪ O’k,t 包含当前噪声图像 ik,t 和不完整的噪声服装 O’k,t，其中后者包含兼容性信息以指导去噪过程。此外，为了类别一致性和个性化，当处理具有类别 ck 的 ik,t 时，我们将类别提示 tck 和用户交互历史 u 引入到反向转换步骤中：</p>
<p>pθ(Ot-1|Ot, tck, u) &#x3D; Πnk&#x3D;1 pθ(ik,t-1|ik,t, tck, O’k,t, u). (9)</p>
<p>这里，pθ(·) 类似于公式 (6) 中的 Pθ(·)，表示在给定指定条件的情况下生成 ik,t-1 作为最和谐匹配项的条件概率。</p>
</li>
</ul>
<p>3.2.2 条件编码器。如图3所示，反向过程中使用了三个条件。对于类别提示 tck，例如“一张帽子的照片，白色背景”，我们遵循 SD [41] 的文本条件机制，为简洁起见，图中省略了该机制。此外，为了捕获兼容性信息和用户偏好，我们为每个不完整的服装 O’k,t 和用户交互历史 u 引入了专用编码器，以获得相互条件和历史条件：</p>
<ul>
<li><p><strong>相互编码器。</strong> 在反向过程中，服装 Ot 可以构建不完整的服装 O’k,t，为在每个扩散步骤 t 生成 ik,t-1 提供兼容性信息。例如，如图3所示，在生成帽子 i1,T-2 时，其他时尚物品 O’1,T-1 &#x3D; {毛衣 i2,T-1, 牛仔裤 i3,T-1, 鞋子 i4,T-1} 提供兼容性信息。为了更好地捕获此信息，我们计算公式 (9) 中每个不完整服装 O’k,t 的平均影响，并将其输入到多层感知器 (MLP) fφ(·) 中以获得相互条件 mk,t：</p>
<p>mk,t &#x3D; fφ(Avg(O’k,t)) &#x3D; fφ(1&#x2F;(n-1) * Σv≠k iv,t), (10)</p>
<p>其中 φ 是 MLP 的可学习参数。此条件通过元素级加法指导去噪过程：</p>
<p>ik,t_mutual &#x3D; (1-η) * ik,t + η * mk,t, (11)</p>
<p>其中 η 表示相互影响比。通过这种方式，相互条件增强了 ik,t-1 和其他时尚物品之间的兼容性。重要的是，所有相互条件 {mk,t}nk&#x3D;1 协同作用，以确保服装 Ot-1 内部的兼容性。</p>
</li>
<li><p><strong>历史编码器。</strong> 用户偏好是从他们在每个类别中的交互历史中捕获的。例如，在生成帽子时（参见图3），用户交互过的帽子在每个扩散步骤中提供个性化信息。形式上，为了生成具有类别 ck 的 ik,t-1（在公式 (9) 中），用户交互历史 u 被分类为 uck &#x3D; {icr k}mr&#x3D;1，表示与类别 ck 中的时尚产品有 m 次交互。利用第3.2.1节中提到的相同预训练编码器 E，我们将这些历史图像压缩到潜在空间，表示为 E(uck) &#x3D; {E(icr k)}mr&#x3D;1。接下来，我们将这些潜在表示平均为历史条件：</p>
<p>hck &#x3D; Avg(E(uck)) &#x3D; 1&#x2F;m * Σmr&#x3D;1 E(icr k). (12)</p>
<p>遵循 [6]，我们通过引入额外的输入通道来扩展 U-Net 的第一个卷积层，其功能是内置的历史编码器，初始化为零。此修改允许 DiFashion 通过将历史条件与公式 (11) 中的 i_mutual 连接起来，从而形成 U-Net 输入 [i_mutual, hck]，从而整合历史条件。</p>
</li>
</ul>
<p>总而言之，DiFashion 通过不同的机制整合了三个条件，指导 U-Net 中的去噪过程。</p>
<p>3.2.3 训练。本质上，DiFashion 是基于 SD 构建的，用于整合三个条件以进行多图像合成。通过结合类别提示 tck、相互条件 mk,t 和历史条件 hk，U-Net 被优化以通过最小化以下目标来预测在正向过程中添加的噪声 εk [22]：</p>
<pre><code>Lθ,φ = 1/n * Σnk=1 E t,εk∼N(0,I) [∥εk - εθ,φ(ik,t, tck, mk,t, hck, t)∥2 2]. (13)
</code></pre>
<p>在无条件图像合成中，无分类器指导 (CFG) [23] 通常用于增强图像保真度并确保</p>
<p>生成图像与输入条件紧密对齐。具体来说，在经典的文本到图像任务中，对于噪声图像 xt，扩散模型在条件场景 txt 和无条件场景 ∅ 下进行训练，其中 ∅ 表示没有条件信息的固定张量。在这些场景下预测的噪声分别表示为 εθ(xt, txt, t) 和 εθ(xt, ∅, t)。在推理过程中，这两个估计值结合起来指导生成过程：</p>
<pre><code>ε̃θ(xt, txt, t) = εθ(xt, ∅, t) + s * [εθ(xt, txt, t) - εθ(xt, ∅, t)], (14)

其中 s ≥ 1 表示条件的指导尺度。
</code></pre>
<p>在 DiFashion 场景中，三个条件指导生成过程：类别提示 tck、相互条件 mk,t 和历史条件 hck。遵循 [6]，我们为这三个条件扩展了 CFG，从而得到推理阶段的修改预测：</p>
<pre><code>ε̃θ,φ(ik,t, tck, mk,t, hck, t)
= εθ,φ(ik,t, ∅,∅,∅,t)
+ st * [εθ,φ(ik,t, tck,∅,∅,t) - εθ,φ(ik,t, ∅,∅,∅,t)]
+ sm * [εθ,φ(ik,t, tck,mk,t,∅,t) - εθ,φ(ik,t, tck,∅,∅,t)]
+ sh * [εθ,φ(ik,t, tck,mk,t,hck,t) - εθ,φ(ik,t, tck,mk,t,∅,t)], (15)

其中 st, sm 和 sh 分别表示类别提示、相互条件和历史条件的指导尺度。为了支持推理的 CFG 方法，DiFashion 在训练期间以特定比例随机遮蔽这三个条件，确保模型参数在公式 (15) 中的所有场景下都得到训练。
</code></pre>
<p>3.2.4 推理。通过训练有素的模型参数，DiFashion 能够执行以下两项任务：</p>
<ul>
<li><p><strong>PFITB。</strong> 这项任务涉及合成一个个性化的新时尚产品，以无缝补充不完整的服装。形式上，给定一个不完整的服装 O’n &#x3D; {ik}n-1k&#x3D;1、一个指定类别 cn、类别提示 tcn 和用户交互历史 ucn，DiFashion 旨在生成缺失的产品 in。请注意，由于存在精确的不完整服装 O’n，因此在每个生成步骤 t 中无需使用替代 O’n,t 来获取相互条件。从纯噪声 in,T ∼ N(0,I) 开始，DiFashion 通过公式 (10) 计算相互条件 mn，并通过公式 (12) 计算历史条件 hcn。有了这些条件，它通过公式 (15) 在每个扩散步骤中预测噪声 ε̃θ,φ(in,t, tcn, mn, hcn, t)，并迭代地去除噪声 in,t → in,t-1，从而得到无缝补充 O’n 的个性化物品 in。</p>
</li>
<li><p><strong>GOR。</strong> GOR 任务旨在根据用户的交互历史 {ck}nk&#x3D;1 和产品类别 {uck}nk&#x3D;1 生成一套新的时尚产品 O &#x3D; {ik}nk&#x3D;1，该产品具有内部兼容性和用户偏好的美学。从纯噪声 OT &#x3D; {ik,T}nk&#x3D;1 ∼ N(0,I) 开始，DiFashion 通过公式 (10) 计算相互条件 {mk,T}nk&#x3D;1，并通过公式 (12) 计算历史条件 {hck}nk&#x3D;1。有了这些条件，它通过公式 (15) 预测噪声 ε̃θ,φ(ik,T, tck, mk,T, hck, T)，并去除这些噪声 OT → OT-1。通过重复此过程，DiFashion 生成最终服装 O &#x3D; O0，该服装具有视觉吸引力并满足用户的时尚品味。</p>
</li>
</ul>
<p><strong>4 实验</strong></p>
<p>我们进行了广泛的实验来回答三个问题：</p>
<ul>
<li><strong>RQ1:</strong> 基于定量评估，DiFashion 在 PFITB 和 GOR 任务中的表现如何，与生成方法和基于检索的 OR 方法相比？</li>
<li><strong>RQ2:</strong> DiFashion 能否在人工参与的定性评估中超越基线？</li>
<li><strong>RQ3:</strong> DiFashion 的设计如何影响性能，例如相互影响比 η、指导尺度 st, sm 和 sh，以及相互编码器中的 MLP 和相互条件和历史条件？</li>
</ul>
<p><strong>4.1 实验设置</strong></p>
<p>4.1.1 数据集。我们使用两个时尚数据集：1）iFashion2 包含预定义服装和单独的时尚产品，以及用户点击行为和产品属性；2）Polyvore-U3 包含预定义服装和用户-服装交互。</p>
<p>对于 iFashion 数据集，我们只保留长度为四的服装以节省计算资源，重点关注基本服装类别。值得注意的是，DiFashion 可以轻松处理更长长度和更多样化类别的服装。对于 Polyvore-U 数据集，我们选择 Polyvore-519，因为它拥有庞大的用户群和不同长度的服装。在这里，长度为三的服装中的物品被视为交互物品，而长度为四的服装被视为交互服装。由于 Polyvore-U 数据集只提供粗略的类别（上衣、下装、鞋子），我们使用 iFashion 数据集微调了一个分类器 Inception-V3 [45] 来预测 Polyvore-U 物品的细粒度类别。我们只保留至少有五套交互服装的活跃用户，遵循 [37] 将交互服装以 8:1:1 的比例划分为训练集、验证集和测试集。数据集统计信息总结在表1中。</p>
<p><strong>表1：两个数据集的统计信息。</strong></p>
<table>
<thead>
<tr>
<th align="left">数据集</th>
<th align="left">#用户</th>
<th align="left">#服装</th>
<th align="left">#物品</th>
<th align="left">#交互</th>
</tr>
</thead>
<tbody><tr>
<td align="left">iFashion</td>
<td align="left">12,806</td>
<td align="left">19,882</td>
<td align="left">344,186</td>
<td align="left">107,396</td>
</tr>
<tr>
<td align="left">Polyvore-U</td>
<td align="left">517</td>
<td align="left">33,906</td>
<td align="left">119,202</td>
<td align="left">33,908</td>
</tr>
</tbody></table>
<p>4.1.2 基线。我们将 DiFashion 与两种任务中的竞争性生成模型进行比较：1）OutfitGAN [37] 利用生成对抗网络为 FITB 任务生成单个时尚图像。2）SD-v1.54 是 SD 的一个版本，带有一个冻结的 CLIP ViT-L&#x2F;14 文本编码器用于文本提示，在 LAION-5B 和“LAION-AestheticsV25+”数据集上训练。3）SD-v25 是另一个版本。4）SD-V 和 SD-H 是 SD 的变体，通过连接集成相互条件和历史条件，而相互编码器中没有 MLP。5）SN-SD [55] 是一种基于检索的 OR 方法，它利用服装中物品之间的相互作用来学习服装表示。我们还将 DiFashion 与基于检索的 OR 方法在检索设置下进行比较：1）Random 是一种朴素策略，随机采样时尚物品用于 PFITB 和 GOR 任务。2）HFN [34] 是一种 POR 方法，它对服装进行建模。</p>
<p>2 <a target="_blank" rel="noopener" href="https://github.com/wenyuer/POG">https://github.com/wenyuer/POG</a>.<br>3 <a target="_blank" rel="noopener" href="https://github.com/lzcn/Fashion-Hash-Net">https://github.com/lzcn/Fashion-Hash-Net</a>.<br>4 <a target="_blank" rel="noopener" href="https://huggingface.co/runwayml/stable-diffusion-v1-5">https://huggingface.co/runwayml/stable-diffusion-v1-5</a>.<br>5 <a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-diffusion-2-base">https://huggingface.co/stabilityai/stable-diffusion-2-base</a>.</p>
<p>生成图像与输入条件紧密对齐。具体来说，在经典的文本到图像任务中，对于噪声图像 xt，扩散模型在条件场景 txt 和无条件场景 ∅ 下进行训练，其中 ∅ 表示没有条件信息的固定张量。在这些场景下预测的噪声分别表示为 εθ(xt, txt, t) 和 εθ(xt, ∅, t)。在推理过程中，这两个估计值结合起来指导生成过程：</p>
<pre><code>ε̃θ(xt, txt, t) = εθ(xt, ∅, t) + s * [εθ(xt, txt, t) - εθ(xt, ∅, t)], (14)

其中 s ≥ 1 表示条件的指导尺度。
</code></pre>
<p>在 DiFashion 场景中，三个条件指导生成过程：类别提示 tck、相互条件 mk,t 和历史条件 hck。遵循 [6]，我们为这三个条件扩展了 CFG，从而得到推理阶段的修改预测：</p>
<pre><code>ε̃θ,φ(ik,t, tck, mk,t, hck, t)
= εθ,φ(ik,t, ∅,∅,∅,t)
+ st * [εθ,φ(ik,t, tck,∅,∅,t) - εθ,φ(ik,t, ∅,∅,∅,t)]
+ sm * [εθ,φ(ik,t, tck,mk,t,∅,t) - εθ,φ(ik,t, tck,∅,∅,t)]
+ sh * [εθ,φ(ik,t, tck,mk,t,hck,t) - εθ,φ(ik,t, tck,mk,t,∅,t)], (15)

其中 st, sm 和 sh 分别表示类别提示、相互条件和历史条件的指导尺度。为了支持推理的 CFG 方法，DiFashion 在训练期间以特定比例随机遮蔽这三个条件，确保模型参数在公式 (15) 中的所有场景下都得到训练。
</code></pre>
<p>3.2.4 推理。通过训练有素的模型参数，DiFashion 能够执行以下两项任务：</p>
<ul>
<li><p><strong>PFITB。</strong> 这项任务涉及合成一个个性化的新时尚产品，以无缝补充不完整的服装。形式上，给定一个不完整的服装 O’n &#x3D; {ik}n-1k&#x3D;1、一个指定类别 cn、类别提示 tcn 和用户交互历史 ucn，DiFashion 旨在生成缺失的产品 in。请注意，由于存在精确的不完整服装 O’n，因此在每个生成步骤 t 中无需使用替代 O’n,t 来获取相互条件。从纯噪声 in,T ∼ N(0,I) 开始，DiFashion 通过公式 (10) 计算相互条件 mn，并通过公式 (12) 计算历史条件 hcn。有了这些条件，它通过公式 (15) 在每个扩散步骤中预测噪声 ε̃θ,φ(in,t, tcn, mn, hcn, t)，并迭代地去除噪声 in,t → in,t-1，从而得到无缝补充 O’n 的个性化物品 in。</p>
</li>
<li><p><strong>GOR。</strong> GOR 任务旨在根据用户的交互历史 {ck}nk&#x3D;1 和产品类别 {uck}nk&#x3D;1 生成一套新的时尚产品 O &#x3D; {ik}nk&#x3D;1，该产品具有内部兼容性和用户偏好的美学。从纯噪声 OT &#x3D; {ik,T}nk&#x3D;1 ∼ N(0,I) 开始，DiFashion 通过公式 (10) 计算相互条件 {mk,T}nk&#x3D;1，并通过公式 (12) 计算历史条件 {hck}nk&#x3D;1。有了这些条件，它通过公式 (15) 预测噪声 ε̃θ,φ(ik,T, tck, mk,T, hck, T)，并去除这些噪声 OT → OT-1。通过重复此过程，DiFashion 生成最终服装 O &#x3D; O0，该服装具有视觉吸引力并满足用户的时尚品味。</p>
</li>
</ul>
<p><strong>4 实验</strong></p>
<p>我们进行了广泛的实验来回答三个问题：</p>
<ul>
<li><strong>RQ1:</strong> 基于定量评估，DiFashion 在 PFITB 和 GOR 任务中的表现如何，与生成方法和基于检索的 OR 方法相比？</li>
<li><strong>RQ2:</strong> DiFashion 能否在人工参与的定性评估中超越基线？</li>
<li><strong>RQ3:</strong> DiFashion 的设计如何影响性能，例如相互影响比 η、指导尺度 st, sm 和 sh，以及相互编码器中的 MLP 和相互条件和历史条件？</li>
</ul>
<p><strong>4.1 实验设置</strong></p>
<p>4.1.1 数据集。我们使用两个时尚数据集：1）iFashion2 包含预定义服装和单独的时尚产品，以及用户点击行为和产品属性；2）Polyvore-U3 包含预定义服装和用户-服装交互。</p>
<p>对于 iFashion 数据集，我们只保留长度为四的服装以节省计算资源，重点关注基本服装类别。值得注意的是，DiFashion 可以轻松处理更长长度和更多样化类别的服装。对于 Polyvore-U 数据集，我们选择 Polyvore-519，因为它拥有庞大的用户群和不同长度的服装。在这里，长度为三的服装中的物品被视为交互物品，而长度为四的服装被视为交互服装。由于 Polyvore-U 数据集只提供粗略的类别（上衣、下装、鞋子），我们使用 iFashion 数据集微调了一个分类器 Inception-V3 [45] 来预测 Polyvore-U 物品的细粒度类别。我们只保留至少有五套交互服装的活跃用户，遵循 [37] 将交互服装以 8:1:1 的比例划分为训练集、验证集和测试集。数据集统计信息总结在表1中。</p>
<p><strong>表1：两个数据集的统计信息。</strong></p>
<table>
<thead>
<tr>
<th align="left">数据集</th>
<th align="left">#用户</th>
<th align="left">#服装</th>
<th align="left">#物品</th>
<th align="left">#交互</th>
</tr>
</thead>
<tbody><tr>
<td align="left">iFashion</td>
<td align="left">12,806</td>
<td align="left">19,882</td>
<td align="left">344,186</td>
<td align="left">107,396</td>
</tr>
<tr>
<td align="left">Polyvore-U</td>
<td align="left">517</td>
<td align="left">33,906</td>
<td align="left">119,202</td>
<td align="left">33,908</td>
</tr>
</tbody></table>
<p>4.1.2 基线。我们将 DiFashion 与两种任务中的竞争性生成模型进行比较：1）OutfitGAN [37] 利用生成对抗网络为 FITB 任务生成单个时尚图像。2）SD-v1.54 是 SD 的一个版本，带有一个冻结的 CLIP ViT-L&#x2F;14 文本编码器用于文本提示，在 LAION-5B 和“LAION-AestheticsV25+”数据集上训练。3）SD-v25 是另一个版本。4）SD-V 和 SD-H 是 SD 的变体，通过连接集成相互条件和历史条件，而相互编码器中没有 MLP。5）SN-SD [55] 是一种基于检索的 OR 方法，它利用服装中物品之间的相互作用来学习服装表示。我们还将 DiFashion 与基于检索的 OR 方法在检索设置下进行比较：1）Random 是一种朴素策略，随机采样时尚物品用于 PFITB 和 GOR 任务。2）HFN [34] 是一种 POR 方法，它对服装进行建模。</p>
<p>2 <a target="_blank" rel="noopener" href="https://github.com/wenyuer/POG">https://github.com/wenyuer/POG</a>.<br>3 <a target="_blank" rel="noopener" href="https://github.com/lzcn/Fashion-Hash-Net">https://github.com/lzcn/Fashion-Hash-Net</a>.<br>4 <a target="_blank" rel="noopener" href="https://huggingface.co/runwayml/stable-diffusion-v1-5">https://huggingface.co/runwayml/stable-diffusion-v1-5</a>.<br>5 <a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-diffusion-2-base">https://huggingface.co/stabilityai/stable-diffusion-2-base</a>.</p>
<p><strong>表2：DiFashion 与生成基线在 PFITB 和 GOR 任务中的定量性能比较。</strong></p>
<p>标有“*”的基线表示预训练模型，“Comp.”和“Per.”分别表示兼容性和个性化。最佳结果以粗体突出显示，次佳结果以下划线表示。</p>
<p><strong>#iFashion PFITB</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">FID↓</th>
<th align="left">IS↑</th>
<th align="left">IS-acc↑</th>
<th align="left">CS↑</th>
<th align="left">CIS↑</th>
<th align="left">LPIPS↓</th>
<th align="left">Comp.↑</th>
<th align="left">Per.↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">OutfitGAN</td>
<td align="left">202.60</td>
<td align="left">9.52</td>
<td align="left">0.19</td>
<td align="left">18.07</td>
<td align="left">16.88</td>
<td align="left">0.63</td>
<td align="left">0.03</td>
<td align="left">21.48</td>
</tr>
<tr>
<td align="left">SD-v1.5*</td>
<td align="left">52.62</td>
<td align="left">22.54</td>
<td align="left">0.76</td>
<td align="left">28.30</td>
<td align="left">38.35</td>
<td align="left">0.68</td>
<td align="left">0.08</td>
<td align="left">46.31</td>
</tr>
<tr>
<td align="left">SD-v2*</td>
<td align="left">54.13</td>
<td align="left">21.66</td>
<td align="left">0.71</td>
<td align="left">29.78</td>
<td align="left">38.66</td>
<td align="left">0.70</td>
<td align="left">0.04</td>
<td align="left">46.52</td>
</tr>
<tr>
<td align="left">SD-v1.5</td>
<td align="left">42.47</td>
<td align="left">26.76</td>
<td align="left">0.83</td>
<td align="left">25.67</td>
<td align="left">44.80</td>
<td align="left">0.62</td>
<td align="left">0.46</td>
<td align="left">53.16</td>
</tr>
<tr>
<td align="left">SD-v2</td>
<td align="left">44.87</td>
<td align="left">25.85</td>
<td align="left">0.80</td>
<td align="left">25.88</td>
<td align="left">44.81</td>
<td align="left">0.66</td>
<td align="left">0.39</td>
<td align="left">52.99</td>
</tr>
<tr>
<td align="left">SD-naive</td>
<td align="left">44.38</td>
<td align="left">25.45</td>
<td align="left">0.80</td>
<td align="left">26.15</td>
<td align="left">44.93</td>
<td align="left">0.66</td>
<td align="left">0.36</td>
<td align="left">52.95</td>
</tr>
<tr>
<td align="left">ControlNet</td>
<td align="left">42.74</td>
<td align="left">27.76</td>
<td align="left">0.81</td>
<td align="left">29.02</td>
<td align="left">41.93</td>
<td align="left">0.67</td>
<td align="left">0.16</td>
<td align="left">49.90</td>
</tr>
<tr>
<td align="left">DiFashion</td>
<td align="left"><strong>34.06</strong></td>
<td align="left"><strong>29.99</strong></td>
<td align="left"><strong>0.90</strong></td>
<td align="left">26.27</td>
<td align="left"><strong>47.36</strong></td>
<td align="left"><strong>0.51</strong></td>
<td align="left"><strong>0.58</strong></td>
<td align="left"><strong>55.86</strong></td>
</tr>
</tbody></table>
<p><strong>#iFashion GOR</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">FID↓</th>
<th align="left">IS↑</th>
<th align="left">IS-acc↑</th>
<th align="left">CS↑</th>
<th align="left">CIS↑</th>
<th align="left">LPIPS↓</th>
<th align="left">Per.↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">SD-v1.5*</td>
<td align="left">38.14</td>
<td align="left">23.20</td>
<td align="left">0.77</td>
<td align="left">28.46</td>
<td align="left">55.84</td>
<td align="left">0.69</td>
<td align="left">46.45</td>
</tr>
<tr>
<td align="left">SD-v2*</td>
<td align="left">40.14</td>
<td align="left">22.19</td>
<td align="left">0.74</td>
<td align="left">29.94</td>
<td align="left">56.00</td>
<td align="left">0.71</td>
<td align="left">46.60</td>
</tr>
<tr>
<td align="left">SD-v1.5</td>
<td align="left">28.31</td>
<td align="left">26.90</td>
<td align="left">0.84</td>
<td align="left">25.62</td>
<td align="left">63.59</td>
<td align="left">0.63</td>
<td align="left">53.24</td>
</tr>
<tr>
<td align="left">SD-v2</td>
<td align="left">30.37</td>
<td align="left">25.82</td>
<td align="left">0.82</td>
<td align="left">25.87</td>
<td align="left">64.51</td>
<td align="left">0.66</td>
<td align="left">53.06</td>
</tr>
<tr>
<td align="left">SD-naive</td>
<td align="left">30.53</td>
<td align="left">25.43</td>
<td align="left">0.81</td>
<td align="left">26.19</td>
<td align="left">64.71</td>
<td align="left">0.67</td>
<td align="left">52.95</td>
</tr>
<tr>
<td align="left">ControlNet</td>
<td align="left">29.41</td>
<td align="left">28.49</td>
<td align="left">0.82</td>
<td align="left">29.03</td>
<td align="left">60.96</td>
<td align="left">0.68</td>
<td align="left">49.91</td>
</tr>
<tr>
<td align="left">DiFashion</td>
<td align="left"><strong>20.21</strong></td>
<td align="left"><strong>30.04</strong></td>
<td align="left"><strong>0.90</strong></td>
<td align="left"><strong>26.10</strong></td>
<td align="left"><strong>67.35</strong></td>
<td align="left"><strong>0.54</strong></td>
<td align="left"><strong>55.54</strong></td>
</tr>
</tbody></table>
<p><strong>#Polyvore-U PFITB</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">FID↓</th>
<th align="left">IS↑</th>
<th align="left">IS-acc↑</th>
<th align="left">CS↑</th>
<th align="left">CIS↑</th>
<th align="left">LPIPS↓</th>
<th align="left">Comp.↑</th>
<th align="left">Per.↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">OutfitGAN</td>
<td align="left">272.82</td>
<td align="left">13.63</td>
<td align="left">0.08</td>
<td align="left">15.08</td>
<td align="left">23.23</td>
<td align="left">0.70</td>
<td align="left">0.00</td>
<td align="left">28.80</td>
</tr>
<tr>
<td align="left">SD-v1.5*</td>
<td align="left">51.34</td>
<td align="left">17.10</td>
<td align="left">0.73</td>
<td align="left">27.46</td>
<td align="left">40.56</td>
<td align="left">0.67</td>
<td align="left">0.70</td>
<td align="left">51.05</td>
</tr>
<tr>
<td align="left">SD-v2*</td>
<td align="left">62.41</td>
<td align="left">14.83</td>
<td align="left">0.68</td>
<td align="left">29.79</td>
<td align="left">40.51</td>
<td align="left">0.71</td>
<td align="left">0.60</td>
<td align="left">51.29</td>
</tr>
<tr>
<td align="left">SD-v1.5</td>
<td align="left">53.72</td>
<td align="left">17.12</td>
<td align="left">0.72</td>
<td align="left">24.31</td>
<td align="left">45.71</td>
<td align="left">0.64</td>
<td align="left">0.75</td>
<td align="left">58.20</td>
</tr>
<tr>
<td align="left">SD-v2</td>
<td align="left">58.13</td>
<td align="left">15.59</td>
<td align="left">0.67</td>
<td align="left">24.49</td>
<td align="left">46.15</td>
<td align="left">0.64</td>
<td align="left">0.71</td>
<td align="left">58.79</td>
</tr>
<tr>
<td align="left">SD-naive</td>
<td align="left">58.22</td>
<td align="left">15.45</td>
<td align="left">0.66</td>
<td align="left">24.23</td>
<td align="left">47.01</td>
<td align="left">0.65</td>
<td align="left">0.73</td>
<td align="left">59.24</td>
</tr>
<tr>
<td align="left">ControlNet</td>
<td align="left">44.31</td>
<td align="left">18.93</td>
<td align="left">0.77</td>
<td align="left">28.67</td>
<td align="left">43.79</td>
<td align="left">0.68</td>
<td align="left">0.73</td>
<td align="left">55.44</td>
</tr>
<tr>
<td align="left">DiFashion</td>
<td align="left"><strong>32.58</strong></td>
<td align="left"><strong>19.67</strong></td>
<td align="left"><strong>0.84</strong></td>
<td align="left"><strong>25.53</strong></td>
<td align="left"><strong>48.82</strong></td>
<td align="left"><strong>0.56</strong></td>
<td align="left"><strong>0.80</strong></td>
<td align="left"><strong>61.44</strong></td>
</tr>
</tbody></table>
<p><strong>#Polyvore-U GOR</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">FID↓</th>
<th align="left">IS↑</th>
<th align="left">IS-acc↑</th>
<th align="left">CS↑</th>
<th align="left">CIS↑</th>
<th align="left">LPIPS↓</th>
<th align="left">Per.↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">SD-v1.5*</td>
<td align="left">42.59</td>
<td align="left">16.95</td>
<td align="left">0.73</td>
<td align="left">27.51</td>
<td align="left">51.68</td>
<td align="left">0.68</td>
<td align="left">50.99</td>
</tr>
<tr>
<td align="left">SD-v2*</td>
<td align="left">53.40</td>
<td align="left">14.88</td>
<td align="left">0.67</td>
<td align="left">29.83</td>
<td align="left">50.91</td>
<td align="left">0.72</td>
<td align="left">51.23</td>
</tr>
<tr>
<td align="left">SD-v1.5</td>
<td align="left">44.73</td>
<td align="left">17.24</td>
<td align="left">0.72</td>
<td align="left">24.34</td>
<td align="left">58.68</td>
<td align="left">0.65</td>
<td align="left">58.16</td>
</tr>
<tr>
<td align="left">SD-v2</td>
<td align="left">41.61</td>
<td align="left">16.33</td>
<td align="left">0.70</td>
<td align="left">23.71</td>
<td align="left">58.86</td>
<td align="left">0.66</td>
<td align="left">58.91</td>
</tr>
<tr>
<td align="left">SD-naive</td>
<td align="left">49.04</td>
<td align="left">15.48</td>
<td align="left">0.67</td>
<td align="left">24.31</td>
<td align="left">59.18</td>
<td align="left">0.66</td>
<td align="left">59.12</td>
</tr>
<tr>
<td align="left">ControlNet</td>
<td align="left">36.05</td>
<td align="left">19.21</td>
<td align="left">0.77</td>
<td align="left">28.72</td>
<td align="left">56.04</td>
<td align="left">0.69</td>
<td align="left">55.40</td>
</tr>
<tr>
<td align="left">DiFashion</td>
<td align="left"><strong>23.47</strong></td>
<td align="left"><strong>18.95</strong></td>
<td align="left"><strong>0.83</strong></td>
<td align="left"><strong>25.35</strong></td>
<td align="left"><strong>60.72</strong></td>
<td align="left"><strong>0.59</strong></td>
<td align="left"><strong>61.16</strong></td>
</tr>
</tbody></table>
<p>兼容性和用户偏好使用内容特征和用户表示与二进制代码。3）HFGN [28] 是另一种使用图建模服装和用户-服装交互的 POR 方法。4）BGN [2] 利用 LSTM 进行捆绑列表推荐。它将服装建模为有序序列，是个性化服装搭配的典型方法。5）BGN-Trans，由我们设计，用 Transformer 替换了 BGN 中的 LSTM，用于个性化服装搭配，类似于 [12] 的相同任务。</p>
<p>4.1.3 评估指标。我们通过以下定量指标将 DiFashion 与上述基线进行比较：</p>
<ul>
<li><strong>生成指标。</strong> 我们使用三个广泛使用的指标评估生成图像的保真度：FID、IS 和 CLIPScore (CS)。为了准确测量 IS，我们微调了 iFashion 数据集上的 Inception-V3 [45]。由于 DiFashion 生成具有指定类别的服装而不是随机生成，我们通过用均匀分布替换生成图像类别的边缘分布来修改 IS。生成图像的分类准确率也报告为 IS-acc。</li>
<li><strong>时尚指标。</strong> 我们引入了三种类型的时尚指标，专为 PFITB 和 GOR 任务量身定制：1）相似性：我们通过生成图像和真实图像之间 CLIP 特征的余弦相似度计算 CLIPImageScore (CIS) 进行语义相似性评估，并采用 LPIPS [56] 进行感知相似性评估。2）兼容性：采用 OutfitGAN [37] 中的兼容性评估器来评估服装兼容性。3）个性化：我们利用 CLIP 提取用户交互物品的图像特征，将其平均作为用户偏好表示，并计算用户偏好与生成图像之间的余弦相似度。</li>
<li><strong>检索准确率。</strong> 对于 PFITB 任务，我们从物品集中随机抽取四个物品作为负样本，然后将其与真实物品组合成每个服装的完整候选集。为了计算检索准确率，我们将每个生成的图像与候选集中的现有物品进行匹配，通过 CLIP 计算的余弦相似度。对于 GOR 任务，候选集由每个指定类别中的所有物品组成。</li>
</ul>
<p>4.1.4 实现细节。我们通过选择最佳检查点和超参数来优化生成模型，这些选择基于四个关键指标（FID、CIS、兼容性和个性化）相对于预训练 SD-v2 的平均改进率。SD-naive、ControlNet 和我们的 DiFashion 在最新的 Stable Diffusion SD-v2 上实现，以进行公平比较。所有基于 DM 的基线和 DiFashion 都具有 1e-5 的固定学习率，并在 iFashion 数据集上进行微调。对于 Polyvore-U 数据集，我们在 iFashion 上训练的模型基础上进行微调，因为 Polyvore-U 的细粒度类别是从 iFashion 上训练的分类器预测的。其他基线根据其默认设置进行调整。</p>
<p>在 DiFashion 中，相互编码器的隐藏维度固定为 256。我们探索了相互影响比 η 在 {0.05, 0.10, 0.15} 中的值，并搜索了条件指导尺度 st、sm 和 sh 在 {10.0,…,15.0}、{2.0,…,7.0} 和 {2.0,…,7.0} 中的值。在训练期间，单个条件以 0.2 的比例随机遮蔽，相互条件和历史条件同时以 0.3 的比例遮蔽。DiFashion 的训练通常需要一个 A100 GPU 天。</p>
<p><strong>4.2 定量评估 (RQ1)</strong></p>
<p>4.2.1 与生成模型的比较。我们首先在表2中比较了 DiFashion 与生成基线在 PFITB 和 GOR 任务中的表现，揭示了以下见解：</p>
<ul>
<li><p>基于 DM 的模型在 PFITB 任务中图像保真度方面优于 OutfitGAN，展示了 DM 在时尚图像合成方面的卓越能力。尽管集成了兼容性模块，OutfitGAN 生成的图像质量较低，导致兼容性较差。此外，由于其模型结构的固有局限性，OutfitGAN 在 GOR 任务中表现不佳。</p>
</li>
<li><p>在每个数据集上进行微调后，SD-v1.5 和 SD-v2 都表现出增强的生成保真度，从而改善了相似性（CIS、LPIPS）、兼容性和个性化。CS 的下降可能源于类别提示缺乏足够的时尚细节，导致生成图像与提示之间的对齐度降低。此外，SD-v1.5 在某些指标上超越了 SD-v2，这可能是由于预训练数据集的差异。</p>
</li>
<li><p>SD-naive 和 ControlNet 集成了相互条件和历史条件，但它们的性能仍然不尽如人意。SD-naive 直接整合了这些条件，而没有额外的模型设计来捕获有用信息，这可能会给 U-Net 引入额外的噪声。至于 ControlNet，它冻结了预训练的 U-Net，只微调了 U-Net 编码层的两个副本以处理条件。然而，固定的 U-Net 可能会限制 DM 建模新数据分布的泛化能力，同时整合多个条件。</p>
</li>
<li><p>DiFashion 在两个数据集的大多数评估指标上都表现出卓越的性能，证实了其在 PFITB 和 GOR 任务中的出色表现。兼容性和个性化的改进突出了其在建模兼容性信息和用户偏好方面的有效性。</p>
</li>
<li><p>PFITB 和 GOR 任务的性能表现出相似的趋势，因为 PFITB 可以被视为 GOR 的简化版本。GOR 任务中的兼容性结果对于所有方法都接近于零，因此为了节省空间而省略了。这些糟糕的结果可能源于生成图像与真实世界图像之间潜在的不一致性，影响了在真实世界图像上训练的兼容性评估器的有效性。在 GOR 任务中生成所有服装图像增加了额外的复杂性，使得定量兼容性评估比 PFITB 任务更具挑战性。兼容性的人工定性评估将在第4.3节中进行。</p>
</li>
</ul>
<p><strong>表3：DiFashion 与基于检索的模型在 PFITB 任务中的比较。“Comp.”和“Per.”分别表示兼容性和个性化。最佳结果以粗体突出显示，次佳结果以下划线表示。</strong></p>
<p><strong>iFashion</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">CS↑</th>
<th align="left">CIS↑</th>
<th align="left">LPIPS↓</th>
<th align="left">Comp.↑</th>
<th align="left">Per.↑</th>
<th align="left">Retrieval↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Random</td>
<td align="left">13.79</td>
<td align="left">48.89</td>
<td align="left">0.42</td>
<td align="left">0.25</td>
<td align="left">50.50</td>
<td align="left">0.17</td>
</tr>
<tr>
<td align="left">HFN</td>
<td align="left">18.44</td>
<td align="left">69.98</td>
<td align="left">0.24</td>
<td align="left">0.55</td>
<td align="left">56.79</td>
<td align="left">0.51</td>
</tr>
<tr>
<td align="left">HFGN</td>
<td align="left">21.64</td>
<td align="left">85.85</td>
<td align="left">0.12</td>
<td align="left">0.75</td>
<td align="left">62.25</td>
<td align="left">0.75</td>
</tr>
<tr>
<td align="left">DiFashion</td>
<td align="left"><strong>23.21</strong></td>
<td align="left"><strong>86.79</strong></td>
<td align="left"><strong>0.11</strong></td>
<td align="left"><strong>0.78</strong></td>
<td align="left"><strong>64.93</strong></td>
<td align="left"><strong>0.76</strong></td>
</tr>
</tbody></table>
<p><strong>Polyvore-U</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">CS↑</th>
<th align="left">CIS↑</th>
<th align="left">LPIPS↓</th>
<th align="left">Comp.↑</th>
<th align="left">Per.↑</th>
<th align="left">Retrieval↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Random</td>
<td align="left">13.90</td>
<td align="left">54.18</td>
<td align="left">0.40</td>
<td align="left">0.45</td>
<td align="left">57.88</td>
<td align="left">0.22</td>
</tr>
<tr>
<td align="left">HFN</td>
<td align="left">15.59</td>
<td align="left">64.36</td>
<td align="left">0.31</td>
<td align="left">0.55</td>
<td align="left">60.31</td>
<td align="left">0.39</td>
</tr>
<tr>
<td align="left">HFGN</td>
<td align="left">20.07</td>
<td align="left">85.26</td>
<td align="left">0.13</td>
<td align="left">0.90</td>
<td align="left">67.12</td>
<td align="left">0.74</td>
</tr>
<tr>
<td align="left">DiFashion</td>
<td align="left"><strong>21.14</strong></td>
<td align="left"><strong>81.92</strong></td>
<td align="left"><strong>0.17</strong></td>
<td align="left"><strong>0.88</strong></td>
<td align="left"><strong>68.49</strong></td>
<td align="left"><strong>0.66</strong></td>
</tr>
</tbody></table>
<p><strong>表4：DiFashion 与基于检索的模型在 GOR 任务中的比较。“Comp.”和“Per.”分别表示兼容性和个性化。最佳结果以粗体突出显示，次佳结果以下划线表示。</strong></p>
<p><strong>iFashion</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">CS↑</th>
<th align="left">CIS↑</th>
<th align="left">LPIPS↓</th>
<th align="left">Comp.↑</th>
<th align="left">Per.↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Random</td>
<td align="left">23.79</td>
<td align="left">69.13</td>
<td align="left">0.45</td>
<td align="left">0.34</td>
<td align="left">60.89</td>
</tr>
<tr>
<td align="left">BGN</td>
<td align="left">23.35</td>
<td align="left">68.53</td>
<td align="left">0.46</td>
<td align="left">0.62</td>
<td align="left">60.48</td>
</tr>
<tr>
<td align="left">BGN-Trans</td>
<td align="left">23.93</td>
<td align="left">69.87</td>
<td align="left">0.45</td>
<td align="left">0.75</td>
<td align="left">61.92</td>
</tr>
<tr>
<td align="left">DiFashion</td>
<td align="left"><strong>25.51</strong></td>
<td align="left"><strong>70.95</strong></td>
<td align="left"><strong>0.47</strong></td>
<td align="left"><strong>0.52</strong></td>
<td align="left"><strong>63.74</strong></td>
</tr>
</tbody></table>
<p><strong>Polyvore-U</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">CS↑</th>
<th align="left">CIS↑</th>
<th align="left">LPIPS↓</th>
<th align="left">Comp.↑</th>
<th align="left">Per.↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Random</td>
<td align="left">21.47</td>
<td align="left">62.77</td>
<td align="left">0.49</td>
<td align="left">0.70</td>
<td align="left">65.82</td>
</tr>
<tr>
<td align="left">BGN</td>
<td align="left">22.33</td>
<td align="left">66.47</td>
<td align="left">0.48</td>
<td align="left">0.95</td>
<td align="left">68.69</td>
</tr>
<tr>
<td align="left">BGN-Trans</td>
<td align="left">22.60</td>
<td align="left">65.33</td>
<td align="left">0.48</td>
<td align="left">0.92</td>
<td align="left">68.75</td>
</tr>
<tr>
<td align="left">DiFashion</td>
<td align="left"><strong>24.36</strong></td>
<td align="left"><strong>65.01</strong></td>
<td align="left"><strong>0.50</strong></td>
<td align="left"><strong>0.80</strong></td>
<td align="left"><strong>69.94</strong></td>
</tr>
</tbody></table>
<p>4.2.2 与基于检索的模型的比较。我们检索 DiFashion 生成图像的近似现有时尚产品，并与基于检索的基线进行比较分析。值得注意的是，DiFashion 在零样本场景下进行评估，因为它在训练时没有接触过负面服装。</p>
<ul>
<li>表3展示了 PFITB 任务中的性能比较，表明 DiFashion 在各种指标上都达到了与基于检索的模型相当的性能。特别是，DiFashion 在 iFashion 数据集上超越了所有基线，强调了其在捕获兼容性信息和用户偏好方面的有效性。这一成功证实了通过检索机制在实际场景中实现 DiFashion 生成图像的实际可行性。</li>
<li>我们在表4中展示了 GOR 任务的检索结果，DiFashion 仍然取得了与基线相当的性能。由于在服装搭配中现有物品的组合多样，准确地将生成的服装与真实情况对齐存在困难，因此此处省略了检索准确率。此外，DiFashion 检索到的服装兼容性低于 PFITB 任务，这可能是由于生成时尚产品与现有产品之间的视觉差异，导致难以实现完美匹配。GOR 任务涉及检索四件物品，而 PFITB 任务只检索单件物品，这可能会显著影响兼容性。</li>
</ul>
<p><strong>4.3 人工定性评估 (RQ2)</strong></p>
<p>为了评估 DiFashion 在保真度、兼容性和个性化方面的定性性能，我们在 Amazon Mechanical Turk6 上进行了人工评估，通过二元选择测试将其与两个竞争基线（SD-v1.5 和 SD-v2）在 iFashion 数据集上进行比较。评估涵盖 PFITB 和 GOR 任务，每个任务有50个案例。对于保真度评估，我们展示了生成的图像&#x2F;服装，并提出了问题：“哪张图像&#x2F;服装能更真实、更完整地描绘时尚产品，并具有干净的背景？”。为了评估兼容性，我们展示了完整的服装，并提出了问题：“哪张时尚图像与这套不完整的服装更兼容？”（针对 PFITB）和“哪套服装更兼容？”（针对 GOR 任务）。在个性化评估中，我们为 PFITB 展示了每个指定类别最多5件用户交互过的物品，为 GOR 任务展示了最多2件。提出的问题是：“考虑到某人过去喜欢的时尚产品，请选择”</p>
<p><strong>表5：人工定性评估结果，其中“±”表示95%置信区间。DiFashion 在 PFITB 和 GOR 任务的所有评估指标上始终优于基线（≥50%）。</strong></p>
<p><strong>PFITB</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">Fidelity</th>
<th align="left">Compatibility</th>
<th align="left">Personalization</th>
</tr>
</thead>
<tbody><tr>
<td align="left">SD-v1.5</td>
<td align="left">64.08±3.08%</td>
<td align="left">60.44±2.42%</td>
<td align="left">68.32±3.47%</td>
</tr>
<tr>
<td align="left">SD-v2</td>
<td align="left">70.04±4.16%</td>
<td align="left">57.48±1.90%</td>
<td align="left">66.40±3.39%</td>
</tr>
</tbody></table>
<p><strong>GOR</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">Fidelity</th>
<th align="left">Compatibility</th>
<th align="left">Personalization</th>
</tr>
</thead>
<tbody><tr>
<td align="left">SD-v1.5</td>
<td align="left">61.56±1.93%</td>
<td align="left">61.20±2.00%</td>
<td align="left">60.80±2.57%</td>
</tr>
<tr>
<td align="left">SD-v2</td>
<td align="left">66.52±2.15%</td>
<td align="left">60.56±1.88%</td>
<td align="left">63.72±1.95%</td>
</tr>
</tbody></table>
<p>6 <a target="_blank" rel="noopener" href="https://www.mturk.com/">https://www.mturk.com/</a>.</p>
<p>哪一个最接近他&#x2F;她的偏好。”我们为每个问卷收集了50个回复。表5报告了 DiFashion 在每个二元选择测试中的选择比例，以及95%置信区间。DiFashion 在所有定性评估指标上始终优于（≥50%）基线，突出了其在满足 GOR 任务三个标准方面的优越性。</p>
<p><strong>4.4 深入分析 (RQ3)</strong></p>
<p>在本节中，我们重点关注 DiFashion 中各种设计的影响，并且仅报告 iFashion 数据集上 PFITB 任务的结果，省略了 GOR 任务或 Polyvore-U 数据集上的结果以节省空间。</p>
<p>4.4.1 超参数分析。</p>
<ul>
<li><strong>相互影响比 η 的影响。</strong> 由 η 控制的相互条件指导 DiFashion 中的生成过程。我们在训练期间改变 η ∈ {0.05, 0.10, 0.15}，并在图4(a)中报告了三个高度相关指标的结果，这些结果揭示了以下见解：1）过小的 η 会削弱兼容性指导，导致保真度、与真实情况的相似性以及兼容性下降。2）相反，过大的 η 会使相互条件主导生成过程，削弱其他条件的影响，导致性能下降。</li>
<li><strong>指导尺度 st, sm 和 sh 的影响。</strong> 我们在推理期间改变三个指导尺度，并在图4(b)中展示了结果，分别关注两个最相关的指标。从图中观察到：1）增加类别指导尺度 st 会提高 CLIPScore 和 IS-acc，表明生成图像与指定类别的一致性得到改善。2）随着相互指导尺度 sm 的增加，FID 和兼容性性能最初会提高，验证了相互条件在兼容性建模中的有效性。然而，过度放大会削弱其他条件的影响，降低保真度和兼容性。因此，仔细选择合适的 sm 对于相互条件至关重要。3）增加历史指导尺度 sh 会导致个性化和与真实情况的相似性得分更高，表明生成图像与用户偏好的一致性得到增强。</li>
</ul>
<p><strong>图4：相互影响比和三个指导尺度的影响。</strong></p>
<p><strong>(a) 相互影响比 η 的影响。</strong></p>
<table>
<thead>
<tr>
<th align="left">CLIP Score</th>
<th align="left">FID</th>
<th align="left">CLIP Image Score</th>
</tr>
</thead>
<tbody><tr>
<td align="left">48</td>
<td align="left">26.60</td>
<td align="left">0.91</td>
</tr>
<tr>
<td align="left">46</td>
<td align="left">26.55</td>
<td align="left">0.90</td>
</tr>
<tr>
<td align="left">44</td>
<td align="left">26.50</td>
<td align="left">0.89</td>
</tr>
<tr>
<td align="left">42</td>
<td align="left">26.45</td>
<td align="left">0.88</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">IS-acc</th>
<th align="left">Compatibility</th>
<th align="left">Personalization</th>
</tr>
</thead>
<tbody><tr>
<td align="left">0.6</td>
<td align="left">47.2</td>
<td align="left">55.4</td>
</tr>
<tr>
<td align="left">0.55</td>
<td align="left">47.0</td>
<td align="left">55.2</td>
</tr>
<tr>
<td align="left">0.50</td>
<td align="left">46.8</td>
<td align="left">55.0</td>
</tr>
<tr>
<td align="left">0.45</td>
<td align="left">46.6</td>
<td align="left">54.8</td>
</tr>
</tbody></table>
<p><strong>(b) 类别指导尺度 st、相互指导尺度 sm 和历史指导尺度 sh 的影响。</strong></p>
<table>
<thead>
<tr>
<th align="left">st</th>
<th align="left">sm</th>
<th align="left">sh</th>
</tr>
</thead>
<tbody><tr>
<td align="left">10</td>
<td align="left">2</td>
<td align="left">2</td>
</tr>
<tr>
<td align="left">11</td>
<td align="left">3</td>
<td align="left">3</td>
</tr>
<tr>
<td align="left">12</td>
<td align="left">4</td>
<td align="left">4</td>
</tr>
<tr>
<td align="left">13</td>
<td align="left">5</td>
<td align="left">5</td>
</tr>
<tr>
<td align="left">14</td>
<td align="left">6</td>
<td align="left">6</td>
</tr>
<tr>
<td align="left">15</td>
<td align="left">7</td>
<td align="left">7</td>
</tr>
</tbody></table>
<p>4.4.2 消融研究。</p>
<ul>
<li><strong>相互编码器中 MLP 的影响。</strong> 为了评估相互编码器中 MLP 的影响，我们比较了 DiFashion 在有 MLP 和没有 MLP 的情况下的性能，如表6所示，重点关注四个关键指标。性能的下降验证了 MLP 在捕获兼容性信息以指导生成过程方面的有效性。缺少 MLP 会在相互条件中引入过多的噪声，阻碍兼容性指导，甚至影响其他条件的指导，导致所有指标的性能下降。</li>
</ul>
<p><strong>表6：DiFashion 在相互编码器中包含（w&#x2F;）和不包含（w&#x2F;o）MLP 时的性能。</strong></p>
<table>
<thead>
<tr>
<th align="left">变体</th>
<th align="left">FID↓</th>
<th align="left">CIS↑</th>
<th align="left">Comp.↑</th>
<th align="left">Per.↑</th>
</tr>
</thead>
<tbody><tr>
<td align="left">w&#x2F;o MLP</td>
<td align="left">100.56</td>
<td align="left">31.72</td>
<td align="left">0.16</td>
<td align="left">38.99</td>
</tr>
<tr>
<td align="left">w&#x2F; MLP</td>
<td align="left"><strong>34.06</strong></td>
<td align="left"><strong>47.36</strong></td>
<td align="left"><strong>0.58</strong></td>
<td align="left"><strong>55.86</strong></td>
</tr>
</tbody></table>
<ul>
<li><strong>相互条件和历史条件的影响。</strong> 为了探索历史条件和相互条件的影响，我们进行了额外的实验，在训练期间排除了相互条件或历史条件。图5中的结果揭示了对相关指标的影响。在子图 (a) 中，缺少相互条件导致保真度和兼容性都下降。这强调了相互条件在捕获兼容性信息方面的功效，它不仅增强了兼容性，还通过额外的细节丰富了生成过程，从而实现了高保真图像生成。在子图 (b) 中，缺少历史条件导致个性化和与真实情况的相似性都下降，证实了历史条件在捕获用户时尚品味方面的有效性。</li>
</ul>
<p><strong>图5：相互条件和历史条件的影响。“w&#x2F;”和“w&#x2F;o”分别表示“有”和“无”。</strong></p>
<p><strong>(a) 相互条件的影响</strong></p>
<table>
<thead>
<tr>
<th align="left">FID</th>
<th align="left">Compatibility</th>
</tr>
</thead>
<tbody><tr>
<td align="left">50</td>
<td align="left">0.9</td>
</tr>
<tr>
<td align="left">40</td>
<td align="left">0.6</td>
</tr>
<tr>
<td align="left">30</td>
<td align="left">0.3</td>
</tr>
<tr>
<td align="left">20</td>
<td align="left">0</td>
</tr>
</tbody></table>
<p><strong>(b) 历史条件的影响</strong></p>
<table>
<thead>
<tr>
<th align="left">CLIP Image Score</th>
<th align="left">Personalization</th>
</tr>
</thead>
<tbody><tr>
<td align="left">50</td>
<td align="left">60</td>
</tr>
<tr>
<td align="left">45</td>
<td align="left">55</td>
</tr>
<tr>
<td align="left">40</td>
<td align="left">50</td>
</tr>
</tbody></table>
<p><strong>4.5 案例研究</strong></p>
<p>在本节中，我们展示了 DiFashion 创建的一些时尚产品和服装示例，并进一步探讨了 DiFashion 在广义 GOR 任务中的能力。</p>
<ul>
<li><strong>DiFashion 用于 PFITB 任务。</strong> 在图6中，我们展示了 PFITB 任务中生成的时尚产品，每个产品都包含在服装内的一个小黑方块中。DiFashion 与两个基线的比较突出了 DiFashion 生成具有卓越保真度和兼容性的时尚图像的能力。</li>
</ul>
<p>用户交互过的每个指定类别的物品</p>
<p><strong>图6：PFITB 任务中生成的图像示例（每个服装中用小黑方块框起来）。</strong></p>
<p>用户交互过的每个指定类别的物品</p>
<p><strong>图7：GOR 任务中生成的服装示例，以及每个类别的用户交互物品。</strong></p>
<ul>
<li><strong>DiFashion 用于 GOR 任务。</strong> 图7展示了 GOR 任务中生成的服装示例以及用户交互历史，并将 DiFashion 与 SD-v1.5 和 SD-v2 进行了比较。比较结果显示 DiFashion 在满足 GOR 任务的三个标准方面具有优越性：1）高保真度：DiFashion 擅长生成更逼真的时尚图像，背景干净；2）兼容性：DiFashion 生成的服装在场合、季节和风格上更和谐；3）个性化：DiFashion 结合了用户的交互历史，生成了更符合用户在颜色、裤长和运动风格方面偏好的个性化服装。</li>
<li><strong>DiFashion 用于广义 GOR 任务。</strong> 考虑到 PFITB 任务是 GOR 任务的简化版本，我们可以将 GOR 任务扩展为更具包容性的形式：当提供用户交互历史和不完整的服装（包括空集）时，广义 GOR 任务旨在合成任意数量的个性化时尚产品，以构成视觉上兼容的服装。如图8所示，DiFashion 能够执行广义 GOR 任务，创建与用户偏好相符的兼容服装。</li>
</ul>
<p><strong>图8：DiFashion 用于广义 GOR 任务。给定用户交互过的物品和不完整的服装（包括空集），DiFashion 可以生成任意数量的个性化时尚物品，以构成吸引人的服装。</strong></p>
<p><strong>5 相关工作</strong></p>
<ul>
<li><strong>服装推荐。</strong> 为了推荐与用户时尚品味相符的兼容服装，服装推荐强调兼容性和用户偏好建模 [15,42]。早期研究将服装视为最小单位，并进行服装级检索以进行推荐 [18,24,28,31,34]，但受限于预定义服装的数量和多样性。个性化服装搭配随后出现，采用物品级检索为特定用户搭配服装 [12,17,20,27]。无论是服装级检索还是物品级检索，当前方法都受限于现有时尚产品，难以满足用户多样化的时尚需求 [25,52]。相比之下，GOR 生成用于服装搭配的新个性化产品，这些产品可以被检索或定制以实现实际应用。</li>
<li><strong>生成式推荐。</strong> 传统推荐系统 [21,29,40] 通常依赖于从现有数据集中检索物品进行个性化推荐。强大的生成模型 [7,14,38,41] 的兴起使推荐系统能够集成 AIGC，朝着更个性化的范式发展，以满足用户多样化的内容需求 [46]。然而，现有工作 [1,32,47,51] 主要利用生成模型来增强传统推荐。相比之下，GeneRec [46] 引入了生成式推荐范式，该范式结合了生成模型，例如 DM 和大型语言模型 (LLM)，以修改现有内容或直接生成新内容。然后将生成的内容集成到现有物品语料库中进行推荐。在此范式中，CG4CTR [50] 利用 DM 根据用户属性生成个性化广告，修改现有产品图像的背景以满足用户偏好。与 CG4CTR 不同，我们提出了时尚领域的一项创新生成任务——生成式服装推荐，以及一个名为 DiFashion 的新模型，旨在生成新服装以满足用户多样化的时尚品味。</li>
<li><strong>时尚领域的扩散模型。</strong> 先前的研究已经探索了 DM 在时尚领域的应用 [8,26]，重点关注以设计师为中心的时尚图像合成。例如，SGDiff [44] 和 FashionDiff [49] 采用不同的元素（例如，草图、颜色、纹理）来生成时尚设计，而 MGD [3] 旨在进行多模态条件时尚图像编辑。尽管取得了这些进展，但利用 DM 进行以用户为中心的时尚图像合成仍未得到充分探索。为了弥补这一空白，DiFashion 结合了用户交互历史，生成多个定制的时尚图像，这些图像具有内部兼容性，用于服装搭配，从而为高度个性化的时尚领域做出贡献。</li>
</ul>
<p><strong>6 结论和未来工作</strong></p>
<p>在这项工作中，我们引入了生成式服装推荐，这是一项致力于合成具有三个关键标准（高保真度、兼容性和个性化）的服装的新任务。为了实现这一目标，我们提出了 DiFashion，这是一种生成式服装推荐模型，它采用三个特定条件来指导多个时尚图像的并行生成。在两个数据集上的实证结果验证了 DiFashion 在 PFITB 和 GOR 任务中的优越性。</p>
<p>这项工作为服装推荐引入了一个新方向，带来了许多值得进一步探索的有前景的想法：1）将更多样化的类别和更详细的时尚属性控制纳入 GOR 任务很有趣；2）设计更好的策略来编码兼容性和个性化。</p>
<p>信息并将这些多模态条件整合到 DM 中是一个有意义的话题；3）在 GOR 任务中识别不断变化的时尚趋势很重要，尤其是在快时尚的背景下 [16,36]；4）通过与用户进行多轮交互，利用 LLM 强大的语义理解能力，获取用户指导的 GOR 任务的明确指令，这为未来的研究带来了希望 [4,30]。</p>
<p><strong>参考文献</strong></p>
<p>[1] Manal A. Alshehri 和 Xiangliang Zhang。2022。用于冷启动新闻推荐的生成对抗零样本学习。在 CIKM。ACM，26-36。<br>[2] Jinze Bai, Chang Zhou, Junshuai Song, Xiaoru Qu, Weiting An, Zhao Li, and Jun Gao。2019。个性化捆绑列表推荐。在 WWW。ACM，60-71。<br>[3] Alberto Baldrati, Davide Morelli, Giuseppe Cartella, Marcella Cornia, Marco Bertini, and Rita Cucchiara。2023。多模态服装设计师：用于时尚图像编辑的人类中心潜在扩散模型。在 arXiv:2304.02051。<br>[4] Keqin Bao, Jizhi Zhang, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng Luo, Fuli Feng, and Qi Tian。2023。推荐系统中大型语言模型的双步接地范式。在 arXiv:2308.08434。<br>[5] Elaine M. Bettaney, Stephen R. Hardwick, Odysseas Zisimopoulos, and Benjamin Paul Chamberlain。2020。电子商务中的时尚服装生成。在 ECML&#x2F;PKDD。Springer，339-354。<br>[6] Tim Brooks, Aleksander Holynski, and Alexei A. Efros。2023。InstructPix2Pix：学习遵循图像编辑指令。在 arXiv:2211.09800。<br>[7] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020。语言模型是少样本学习者。NeurIPS 33 (2020), 1877-1901。<br>[8] Shidong Cao, Wenhao Chai, Shengyu Hao, and Gaoang Wang。2023。图像参考引导的时尚设计与扩散模型的结构感知迁移。在 CVPRW。IEEE，3524-3528。<br>[9] Marjan Celikik, Matthias Kirmse, Timo Denk, Pierre Gagliardi, Sahar Mbarek, Duy Pham, and Ana Peleteiro Ramallo。2021。服装生成与推荐——一项实验研究。在 FashionxRecsys。ACM，117-137。<br>[10] Huiyuan Chen, Yusan Lin, Fei Wang, and Hao Yang。2021。上衣、下装和鞋子：通过交叉注意力张量网络构建胶囊衣橱。在 RecSys。453-462。<br>[11] Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao, Enze Xie, Yue Wu, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, and Zhenguo Li。2023。PixArt-α：用于逼真文本到图像合成的扩散 Transformer 的快速训练。在 arXiv:2310.00426。<br>[12] Wen Chen, Pipei Huang, Jiaming Xu, Xin Guo, Cheng Guo, Fei Sun, Chao Li, Andreas Pfadler, Huan Zhao, and Binqiang Zhao。2019。POG：阿里巴巴 iFashion 的个性化服装生成推荐。在 KDD。ACM，2662-2670。<br>[13] Zeyu Cui, Zekun Li, Shu Wu, Xiao-Yu Zhang, and Liang Wang。2019。整体着装：基于节点图神经网络的服装兼容性学习。在 WWW。ACM，307-317。<br>[14] Prafulla Dhariwal and Alexander Nichol。2021。扩散模型在图像合成方面超越 GAN。NeurIPS 34 (2021), 8780-8794。<br>[15] Yujuan Ding, Zhihui Lai, P.Y. Mok, and Tat-Seng Chua。2023。时尚推荐的计算技术：一项调查。ACM Comput. Surv. 56, 5 (2023)。<br>[16] Yujuan Ding, Yunshan Ma, Lizi Liao, Wai Keung Wong, and Tat-Seng Chua。2021。利用多重关系进行基于社交媒体的时尚趋势预测。IEEE Transactions on Multimedia 24 (2021), 2287-2299。<br>[17] Yujuan Ding, P.Y. Mok, Yunshan Ma, and Yi Bin。2023。具有用户协调偏好学习的个性化时尚服装生成。IPM 60, 5 (2023), 103434。<br>[18] Xue Dong, Xuemeng Song, Fuli Feng, Peiguang Jing, Xin-Shun Xu, and Liqiang Nie。2019。通过服装和用户建模创建个性化胶囊衣橱。在 MM。ACM，302-310。<br>[19] Ziyue Guo, Zongyang Zhu, Yizhi Li, Shidong Cao, Hangyue Chen, and Gaoang Wang。2023。AI 辅助时尚设计：一项综述。IEEE Access (2023)。<br>[20] Xintong Han, Zuxuan Wu, Yu-Gang Jiang, and Larry S. Davis。2017。使用双向 LSTM 学习时尚兼容性。在 MM。ACM，1078-1086。<br>[21] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang。2020。Lightgcn：简化和增强图卷积网络以进行推荐。在 SIGIR。ACM，639-648。<br>[22] Jonathan Ho, Ajay Jain, and Pieter Abbeel。2020。去噪扩散概率模型。NeurIPS 33 (2020), 6840-6851。<br>[23] Jonathan Ho and Tim Salimans。2022。无分类器扩散指导。在 arXiv:2207.12598。<br>[24] Yang Hu, Xi Yi, and Larry S. Davis。2015。协同时尚推荐：一种函数张量分解方法。在 MM。ACM，129-138。<br>[25] Anish Jain, Diti Modi, Rudra Jikadra, and Shweta Chachra。2019。时尚服装的文本到图像生成。在 INDIACom。IEEE，355-358。<br>[26] Chaerin Kong, Dong Hyeon Jeon, Ohjoon Kwon, and Nojun Kwak。2023。利用现成扩散模型进行多属性时尚图像操作。在 WACV。IEEE，848-857。<br>[27] Kedan Li, Chen Liu, and David Forsyth。2019。连贯且可控的服装生成。在 arXiv:1906.07273。<br>[28] Xingchen Li, Xiang Wang, Xiangnan He, Long Chen, Jun Xiao, and Tat-Seng Chua。2020。用于个性化服装推荐的分层时尚图网络。在 SIGIR。ACM，159-168。<br>[29] Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara。2018。用于协同过滤的变分自编码器。在 WWW。ACM，689-698。<br>[30] Xinyu Lin, Wenjie Wang, Yongqi Li, Fuli Feng, See-Kiong Ng, and Tat-Seng Chua。2023。连接大型语言模型和推荐的多方面范式。在 arXiv:2310.06491。<br>[31] Yusan Lin, Maryam Moosaei, and Hao Yang。2020。OutfitNet：基于注意力的多实例学习的时尚服装推荐。在 WWW。ACM，77-87。<br>[32] Qijiong Liu, Nuo Chen, Tetsuya Sakai, and Xiao-Ming Wu。2023。ONCE：通过开放和闭源大型语言模型增强基于内容的推荐。<br>[33] Zhi Lu, Yang Hu, Yan Chen, and Bing Zeng。2021。具有可学习锚点的个性化服装推荐。在 CVPR。IEEE，12717-12726。<br>[34] Zhi Lu, Yang Hu, Yunchao Jiang, Yan Chen, and Bing Zeng。2019。学习用于个性化时尚推荐的二进制代码。在 CVPR。IEEE，10554-10562。<br>[35] Calvin Luo。2022。理解扩散模型：一个统一的视角。在 arXiv:2208.11970。<br>[36] Yunshan Ma, Yujuan Ding, Xun Yang, Lizi Liao, Wai Keung Wong, and Tat-Seng Chua。2020。知识增强的神经时尚趋势预测。在 ICMR。ACM，82-90。<br>[37] Maryam Moosaei, Yusan Lin, Ablaikhan Akhazhanov, Huiyuan Chen, Fei Wang, and Hao Yang。2022。OutfitGAN：学习用于生成时尚服装的兼容物品。在 CVPRW。IEEE，2272-2276。<br>[38] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022。训练语言模型以通过人工反馈遵循指令。NeurIPS 35 (2022), 27730-27744。<br>[39] William Peebles and Saining Xie。2023。具有 Transformer 的可扩展扩散模型。在 ICCV。IEEE，4195-4205。<br>[40] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme。2009。BPR：来自隐式反馈的贝叶斯个性化排名。在 UAI。AUAI Press，452-461。<br>[41] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer。2022。使用潜在扩散模型进行高分辨率图像合成。在 CVPR。10684-10695。<br>[42] Rohan Sarkar, Navaneeth Bodla, Mariya I Vasileva, Yen-Liang Lin, Anurag Beniwal, Alan Lu, and Gerard Medioni。2023。服装 Transformer：学习用于时尚推荐的服装表示。在 WACV。IEEE，3601-3609。<br>[43] Shukla Sharma, Ludovic Koehl, Pascal Bruniaux, Xianyi Zeng, and Zhujun Wang。2021。开发智能数据驱动系统以推荐个性化时尚设计解决方案。Sensors 21, 12 (2021), 4239。<br>[44] Zhengwentai Sun, Yanghong Zhou, Honghong He, and P.Y. Mok。2023。SGDiff：用于时尚合成的风格引导扩散模型。在 MM。ACM，8433-8442。<br>[45] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna。2016。重新思考用于计算机视觉的 Inception 架构。在 CVPR。IEEE，2818-2826。<br>[46] Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, and Tat-Seng Chua。2023。生成式推荐：迈向下一代推荐范式。在 arXiv:2304.03516。<br>[47] Wenjie Wang, Yiyan Xu, Fuli Feng, Xinyu Lin, Xiangnan He, and Tat-Seng Chua。2023。扩散推荐模型。在 SIGIR。ACM，832-841。<br>[48] Hui Wu, Yupeng Gao, Xiaoxiao Guo, Ziad Al-Halah, Steven Rennie, Kristen Grauman, and Rogerio Feris。2021。FashionIQ：一个用于通过自然语言反馈检索图像的新数据集。在 CVPR。11307-11317。<br>[49] Han Yan, Haijun Zhang, Xiangyu Mu, Jicong Fan, and Zhao Zhang。2023。FashionDiff：一种使用成对时尚元素进行智能设计的可控扩散模型。在 MM。ACM，1401-1411。<br>[50] Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, and Yifan Zeng。2024。使用 Stable Diffusion 模型进行点击率的新创意生成管道。在 arXiv:2401.10934。<br>[51] Zhengyi Yang, Jiancan Wu, Zhicai Wang, Xiang Wang, Yancheng Yuan, and Xiangnan He。2023。生成你喜欢的：通过引导扩散重塑序列推荐。在 arXiv:2310.20453。<br>[52] Cong Yu, Yang Hu, Yan Chen, and Bing Zeng。2019。个性化时尚设计。在 ICCV。IEEE，9046-9055。<br>[53] Yifei Yuan and Wai Lam。2021。通过多轮自然语言反馈进行对话式时尚图像检索。在 SIGIR。839-848。</p>
<h2 id="图片翻译"><a href="#图片翻译" class="headerlink" title="图片翻译"></a>图片翻译</h2><h2 id="图片翻译-1"><a href="#图片翻译-1" class="headerlink" title="图片翻译"></a>图片翻译</h2><p><strong>图1：服装推荐的演变。</strong></p>
<ul>
<li><p><strong>预定义服装推荐</strong></p>
<ul>
<li>交互历史 -&gt; 服装推荐 -&gt; 服装级检索 -&gt; 时尚服装数据库</li>
<li>检索到的预定义服装</li>
</ul>
</li>
<li><p><strong>个性化服装搭配</strong></p>
<ul>
<li>交互历史 -&gt; 服装推荐 -&gt; 物品级检索 -&gt; 时尚物品数据库</li>
<li>将检索到的物品组合成一套服装</li>
</ul>
</li>
<li><p><strong>受现有时尚产品限制</strong></p>
</li>
<li><p><strong>生成式服装推荐</strong></p>
<ul>
<li>交互历史 -&gt; 服装推荐 -&gt; 生成 -&gt; 新服装</li>
<li>定制 &#x2F; 检索 -&gt; 时尚制造商 &#x2F; 时尚物品数据库</li>
</ul>
</li>
</ul>
<p><strong>图2：DiFashion 在个性化填空和生成式服装推荐任务中的演示。</strong></p>
<ul>
<li><p><strong>个性化填空</strong></p>
<ul>
<li>交互历史 -&gt; 帽子？-&gt; DiFashion -&gt; 检索&#x2F;定制</li>
<li>交互历史 -&gt; 外套、衬衫、裤子、鞋子 -&gt; DiFashion -&gt; 检索&#x2F;定制</li>
</ul>
</li>
<li><p><strong>生成式服装推荐</strong></p>
<ul>
<li>交互历史 -&gt; DiFashion -&gt; 生成新服装</li>
</ul>
</li>
</ul>
<p><strong>图3：DiFashion 概述：</strong> 它在正向过程中通过高斯噪声逐渐破坏服装图像，然后通过并行条件去噪过程重建这些图像。去噪过程由三个条件指导：类别提示、相互条件和历史条件。</p>
<ul>
<li><p><strong>类别提示</strong></p>
<ul>
<li>“一张帽子的照片（类别），白色背景。”</li>
</ul>
</li>
<li><p><strong>相互条件</strong></p>
<ul>
<li>用户交互过的帽子</li>
</ul>
</li>
<li><p><strong>历史条件</strong></p>
<ul>
<li>用户</li>
</ul>
</li>
<li><p><strong>元素级加法</strong></p>
</li>
<li><p><strong>连接</strong></p>
</li>
</ul>
<p><strong>图4：相互影响比和三个指导尺度的影响。</strong></p>
<p><strong>(a) 相互影响比 η 的影响。</strong></p>
<ul>
<li><strong>CLIP Score</strong></li>
<li><strong>FID</strong></li>
<li><strong>CLIP Image Score</strong></li>
<li><strong>IS-acc</strong></li>
<li><strong>Compatibility</strong></li>
<li><strong>Personalization</strong></li>
</ul>
<p><strong>(b) 类别指导尺度 st、相互指导尺度 sm 和历史指导尺度 sh 的影响。</strong></p>
<ul>
<li><strong>st</strong></li>
<li><strong>sm</strong></li>
<li><strong>sh</strong></li>
</ul>
<p><strong>图5：相互条件和历史条件的影响。“w&#x2F;”和“w&#x2F;o”分别表示“有”和“无”。</strong></p>
<p><strong>(a) 相互条件的影响</strong></p>
<ul>
<li><strong>FID</strong></li>
<li><strong>Compatibility</strong></li>
</ul>
<p><strong>(b) 历史条件的影响</strong></p>
<ul>
<li><strong>CLIP Image Score</strong></li>
<li><strong>Personalization</strong></li>
</ul>
<p><strong>图6：PFITB 任务中生成的图像示例（每个服装中用小黑方块框起来）。</strong></p>
<ul>
<li><strong>用户交互过的每个指定类别的物品</strong></li>
</ul>
<p><strong>图7：GOR 任务中生成的服装示例，以及每个类别的用户交互物品。</strong></p>
<ul>
<li><strong>用户交互过的每个指定类别的物品</strong></li>
</ul>
<p><strong>图8：DiFashion 用于广义 GOR 任务。给定用户交互过的物品和不完整的服装（包括空集），DiFashion 可以生成任意数量的个性化时尚物品，以构成吸引人的服装。</strong></p>
<ul>
<li><strong>用户交互过的每个指定类别的物品</strong></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/06/26/Fashion/" rel="prev" title="Fashion++">
                  <i class="fa fa-angle-left"></i> Fashion++
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">L</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
